% $Log: abstract.tex,v $
% Revision 1.1  93/05/14  14:56:25  starflt
% Initial revision
% 
% Revision 1.1  90/05/04  10:41:01  lwvanels
% Initial revision
% 
%
%% The text of your abstract and nothing else (other than comments) goes here.
%% It will be single-spaced and the rest of the text that is supposed to go on
%% the abstract page will be generated by the abstractpage environment.  This
%% file should be \input (not \include 'd) from cover.tex.
Towards modeling the real-world phenomenons with partial differential equations that involve uncertainties, one of the major difficulties is a set of phenomena known as the curse of dimensionality. Luckily, very often the variability of physical quantities derived from the model can be captured by a few features on the coefficient fields, with what so called model reduction techniques. On the other hand, neural networks are good at finding hidden maps on the data. For example, one can use neural-networks based methods to parametrize the physical quantity of interest as a function of input coefficients. In that case, the representability of such quantity can be justified by viewing the neural networks as performing time evolution to find the solution to the model. Indeed, in this thesis, we review a surrogate forward neural network model used to solve two notable partial differential equations in engineering and physics. Also, we explain possibilities that neural networks comes forward throw looking at the mathematical analysis of a well known method, namely finite element method.
\keywords{Partial Differential Equations, Finite Difference Method, Finite Element Method, Uncertainty Quantification}

