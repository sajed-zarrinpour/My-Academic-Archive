\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\babel@aux{english}{}
\HyPL@Entry{1<</P()>>}
\HyPL@Entry{2<</S/r>>}
\@writefile{toc}{\contentsline {section}{Abstract}{ii}{section*.1}}
\citation{khatam2015vivo}
\citation{tanner2002comparison}
\citation{han2011development}
\citation{azar2002methods}
\citation{azar2001deformable}
\citation{del2008finite}
\citation{martinez2017finite}
\citation{del2008finite}
\citation{martinez2017finite}
\citation{azar2001deformable}
\citation{martinez2017finite}
\citation{martinez2017finite}
\citation{geneva2020modeling}
\citation{smaoui2004modelling}
\citation{lagaris2000neural}
\citation{beck2019machine}
\citation{zhang2019quantifying}
\citation{parisi2003solving}
\HyPL@Entry{6<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background \& Motivation}{1}{section.1.1}}
\newlabel{sec:Background_And_Motivations}{{1.1}{1}{Background \& Motivation}{section.1.1}{}}
\citation{stavroulakis1999partial}
\citation{stavroulakis1999partial}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Partial Differential Equations}{3}{section.1.2}}
\newlabel{sec:PDE}{{1.2}{3}{Partial Differential Equations}{section.1.2}{}}
\citation{UQIntro_Sullivan}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Uncertainty Quantification}{4}{section.1.3}}
\citation{mcculloch1943logical}
\citation{hebb1949organization}
\citation{schmidhuber2015deep}
\citation{ivakhnenko1973cybernetic}
\citation{ivakhnenko1967cybernetics}
\citation{schmidhuber2015deep}
\citation{dreyfus1990artificial}
\citation{mizutani2000derivation}
\citation{kelley1960gradient}
\citation{bryson1961gradient}
\citation{linnainmaa1970representation}
\citation{linnainmaa1976taylor}
\citation{smolensky1986information}
\citation{le2013building}
\citation{MLDict}
\citation{MLDict}
\citation{MLDict}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Artificial Neural Network}{5}{section.1.4}}
\citation{weinan2018deep}
\citation{wang2019prediction}
\citation{raissi2017physics}
\citation{Base_paper}
\citation{raissi2018deep}
\citation{Base_paper}
\citation{weinan2018deep}
\citation{khoo2019solving}
\citation{lagaris1998artificial}
\citation{long2017pde}
\citation{rudd2015constrained}
\citation{han2018solving}
\newlabel{regression_key_task}{{1.4}{9}{Artificial Neural Network}{equation.1.4.4}{}}
\citation{forsythe1960finite}
\citation{smith1985numerical}
\citation{morton2005numerical}
\citation{suli2012lecture}
\citation{johnson2012numerical}
\citation{zienkiewicz1977finite}
\citation{cook2007concepts}
\citation{dahmen1997multiscale}
\citation{lepik2005numerical}
\citation{moukalled2016finite}
\citation{leveque2002finite}
\citation{liu2003smoothed}
\citation{liu2009meshfree}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}An Overview of Classical Numerical Methods}{10}{section.1.5}}
\newlabel{sec:overviewof_FEM_FDM}{{1.5}{10}{An Overview of Classical Numerical Methods}{section.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Problem Statement and Contributions}{11}{section.1.6}}
\newlabel{problem:effective_conductance}{{1.5}{12}{Problem Statement and Contributions}{equation.1.6.5}{}}
\newlabel{general_Shrodinger_equation_form}{{1.6}{12}{Problem Statement and Contributions}{equation.1.6.6}{}}
\newlabel{NLSE}{{1.8}{12}{Problem Statement and Contributions}{equation.1.6.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Thesis Structure}{13}{section.1.7}}
\citation{UQIntro_Sullivan}
\citation{UQIntro_Sullivan}
\citation{rudin1991functional}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Mathematical Preliminaries}{14}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Functional Analysis}{14}{section.2.1}}
\newlabel{sec:functional_analysis}{{2.1}{14}{Functional Analysis}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Measure Spaces}{14}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Lebesgue Integration}{16}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Sobolev Spaces}{18}{subsection.2.1.3}}
\citation{suli2012lecture}
\citation{johnson2012numerical}
\citation{douglas2003tutorial}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Finite Element Method}{20}{section.2.2}}
\newlabel{sec:finite_element_method}{{2.2}{20}{Finite Element Method}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Weak Solutions to Elliptic Problems}{21}{subsection.2.2.1}}
\newlabel{elliptic_equation}{{2.4}{21}{Weak Solutions to Elliptic Problems}{equation.2.2.4}{}}
\newlabel{bc_of_elliptic_equation}{{2.5}{21}{Weak Solutions to Elliptic Problems}{equation.2.2.4}{}}
\newlabel{uniform_ellipticity}{{2.6}{22}{Weak Solutions to Elliptic Problems}{equation.2.2.6}{}}
\newlabel{weak_sulotion_definition}{{2.7}{22}{}{equation.2.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}The Self-Adjoint Elliptic Problem}{24}{subsection.2.2.2}}
\newlabel{self_adjoint_elliptic_equation}{{2.8}{24}{The Self-Adjoint Elliptic Problem}{equation.2.2.8}{}}
\citation{weinan2018deep}
\citation{cybenko1989approximation}
\citation{li1999alpha}
\citation{hofbauer1990adaptive}
\citation{lu2017expressive}
\citation{he2016deep}
\citation{lin2018resnet}
\citation{hanin2017approximating}
\citation{tikk2003survey}
\citation{kratsios2019universal}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Neural Network}{26}{section.2.3}}
\newlabel{sec:neural_network}{{2.3}{26}{Neural Network}{section.2.3}{}}
\newlabel{universal_approximation_theorem}{{2.18}{27}{}{thm.2.18}{}}
\citation{hornik1989multilayer}
\citation{sonoda2017neural}
\citation{petersen2018optimal}
\citation{ismailov2014approximation}
\citation{lin2018resnet}
\citation{he2016deep}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Mathematical Models}{29}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Effective Coefficients for Inhomogeneous Elliptic Equation}{29}{section.3.1}}
\newlabel{def:coefficient_field_for_effective_conductance}{{3.1}{29}{Effective Coefficients for Inhomogeneous Elliptic Equation}{equation.3.1.1}{}}
\newlabel{eq:effective_conductance_variational_form}{{3.2}{29}{Effective Coefficients for Inhomogeneous Elliptic Equation}{equation.3.1.2}{}}
\newlabel{eq:effective_conductance_pde_form}{{3.3}{30}{Effective Coefficients for Inhomogeneous Elliptic Equation}{equation.3.1.3}{}}
\newlabel{eq:Jtilda}{{3.4}{30}{Effective Coefficients for Inhomogeneous Elliptic Equation}{equation.3.1.4}{}}
\newlabel{def:L_a}{{3.13}{32}{Effective Coefficients for Inhomogeneous Elliptic Equation}{equation.3.1.13}{}}
\newlabel{def:b_a}{{3.14}{32}{Effective Coefficients for Inhomogeneous Elliptic Equation}{equation.3.1.14}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Calculate $U_a$\relax }}{34}{algorithm.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{eq:effective_conductance_FDM_Matrix_form}{{1}{34}{Calculate $U_a$\relax }{algorithm.1}{}}
\newlabel{_A_eff_matriceForm}{{3.15}{34}{Effective Coefficients for Inhomogeneous Elliptic Equation}{equation.3.1.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Theoretical Justification of Deep Neural Network Representation}{34}{subsection.3.1.1}}
\newlabel{def:Epsilon}{{3.16}{35}{}{equation.3.1.16}{}}
\newlabel{steepest_decent}{{3.17}{35}{Theoretical Justification of Deep Neural Network Representation}{equation.3.1.17}{}}
\newlabel{eq:iterationschema_noisy_steepest_decent}{{3.18}{36}{Theoretical Justification of Deep Neural Network Representation}{equation.3.1.18}{}}
\newlabel{ass:lambda_a_properties}{{3.19}{36}{}{equation.3.1.19}{}}
\newlabel{ass:ass2}{{3.20}{36}{}{equation.3.1.20}{}}
\newlabel{lemma1}{{9}{36}{}{theorem.9}{}}
\newlabel{eq:toproof_in_lemma1}{{3.23}{36}{}{equation.3.1.23}{}}
\newlabel{theorem:one}{{3.4}{37}{}{thm.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}None Linear Schr\"{o}dinger Equation with Inhomogeneous Background Potential}{40}{section.3.2}}
\newlabel{eq:NLSE}{{3.29}{40}{None Linear Schr\"{o}dinger Equation with Inhomogeneous Background Potential}{equation.3.2.29}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Coefficient matrix\relax }}{41}{algorithm.2}}
\newlabel{alg:NLSE_FDM_Matrix}{{2}{41}{Coefficient matrix\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{44}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Neural Network Architecture}{44}{section.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4-1}{\ignorespaces Single convolutional layer.\relax }}{45}{figure.caption.3}}
\newlabel{fig:NLSE_NN_Structure}{{4-1}{45}{Single convolutional layer.\relax }{figure.caption.3}{}}
\newlabel{ECIM_AnalythicalSolution}{{4.1}{46}{Neural Network Architecture}{equation.4.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4-2}{\ignorespaces Neural network architecture for approximating $A_\text  {eff}$ in 1D.\relax }}{46}{figure.caption.4}}
\newlabel{fig:ECIM_NN_Structure}{{4-2}{46}{Neural network architecture for approximating $A_\text {eff}$ in 1D.\relax }{figure.caption.4}{}}
\citation{Base_paper}
\@writefile{lof}{\contentsline {figure}{\numberline {4-3}{\ignorespaces Output of the first stage of the neural network in approximating $A_\text  {eff}$ in 1D.\relax }}{47}{figure.caption.5}}
\newlabel{fig:output_of_the_second_stage}{{4-3}{47}{Output of the first stage of the neural network in approximating $A_\text {eff}$ in 1D.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Effective Conductance in Inhomogeneus Media}{47}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Nonlinear Shr\"{o}dinger Equation}{47}{section.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4-4}{\ignorespaces Committed error per sample over the prediction set\relax }}{48}{figure.caption.6}}
\newlabel{fig:ECIM_error_bar}{{4-4}{48}{Committed error per sample over the prediction set\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4-5}{\ignorespaces Committed error per sample over the prediction set distribution\relax }}{48}{figure.caption.7}}
\newlabel{fig:ECIM_error_percentage}{{4-5}{48}{Committed error per sample over the prediction set distribution\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4-6}{\ignorespaces Committed error per sample over the prediction set\relax }}{49}{figure.caption.8}}
\newlabel{fig:NLSE_error_bar}{{4-6}{49}{Committed error per sample over the prediction set\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4-7}{\ignorespaces Committed error per sample over the prediction set\relax }}{49}{figure.caption.9}}
\newlabel{fig:NLSE_error_percentage}{{4-7}{49}{Committed error per sample over the prediction set\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Conclusion}{49}{section.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Future Work}{50}{section.4.5}}
\@input{biblio.aux}
\@input{appa.aux}
